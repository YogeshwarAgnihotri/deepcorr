import numpy as np
from shared.data_processing import (
    generate_flow_pairs_to_memmap, 
)

from shared.train_test_split import (
    calc_train_test_indexes_using_ratio,
)

from shared.data_handling import (
    load_dataset_deepcorr, 
    load_pregenerated_memmap_dataset,
    save_memmap_info_flow_pairs_and_labels, 
)

def load_prepare_dataset(pregenerated_dataset_path, load_data_set_into_memory):
    """Load and prepare the dataset for training."""
    # Load pregenerated dataset
    flow_pairs_train, labels_train, flow_pairs_test, labels_test = (
        load_pregenerated_memmap_dataset(pregenerated_dataset_path)
    )

    # Doesn't seem to make any difference in speed,
    # maybe because the dataset is small.
    # Leaving it in for now.
    if load_data_set_into_memory:
        flow_pairs_train, labels_train, flow_pairs_test, labels_test = [
            np.array(arr) for arr in (
                flow_pairs_train, labels_train, flow_pairs_test, labels_test
            )
        ]

    return flow_pairs_train, labels_train, flow_pairs_test, labels_test

def save_dataset_info(config,
                      flow_pairs_train,
                      labels_train, 
                      flow_pairs_test,
                      labels_test,
                      run_folder_path):
    if config['load_pregenerated_dataset'] == False:
        # In this case, the dataset is generated by this script and not loaded
        # from a pregenerated memmap file. Therefore, save the used dataset 
        # shapes to a JSON file. This is needed for later loading of the
        # memmap arrays.
        save_memmap_info_flow_pairs_and_labels(flow_pairs_train, 
                                           labels_train, 
                                           flow_pairs_test, 
                                           labels_test, 
                                           run_folder_path)