#####################Dataset loading, splitting and generating settings#####################
load_pregenerated_dataset: True  # If true, load the dataset; otherwise, generate the dataset
pregenerated_dataset_path: "/home/yogeshwar/datasets/deepcorr_pregen/deepcorr_9008_2252"  # Path to the preprocessed dataset
#pregenerated_dataset_path: "/home/yagnihotri/datasets/deepcorr/deepcorr_pregen/deepcorr_9008_2252"  # Path to the preprocessed dataset

# Dataset generation settings
# ONLY USED IF load_pregenerated_dataset IS FALSE
base_dataset_path: "/home/yogeshwar/datasets/deepcorr_original"  # Path to the DeepCorr dataset
#base_dataset_path: "/home/yagnihotri/datasets/deepcorr_original"  # Path to the DeepCorr dataset

train_ratio: 0.8  # Training set ratio
flow_size: 300  # Flow sizes
negative_samples: 1  # Number of negative samples
load_all_data: False  # If true, load all data; otherwise, only load flows with minimum specified packets

# Load dataset fully into memory, if false keeps using memmap arrays
load_dataset_into_memory: False

######################################Run Settings###########################################
model_type: "xgbClassifier"  # "decision_tree" , "random_forest", "xgbClassifier"
run_folder_path: "/home/yogeshwar/master_thesis_corr/lightcorr"  # Path to the folder where the run folder will be created
#run_folder_path: "/home/yagnihotri/projects/corr/lightcorr"

hyperparameter_search_type: "none"  # Type of hyperparameter search ("none", "grid_search", "halving_grid_search" "random_search")
selected_hyperparameter_grid: "none"  # Name of the hyperparameter grid to use (see below)

######################################Validation Settings######################################
validation_settings:
  run_validation: true # If true, run validation, otherwise skip validation
  roc_plot_enabled: true  # If true, generate ROC plot
  cross_validation:
    cv: 5  # Number of folds for cross-validation
    n_jobs: -1  # Number of jobs to run in parallel. -1 means using all processors
    verbose: 100  # Verbosity level for cross-validation

######################################Hyperparameter Settings#################################
hyperparameter_search_settings:
  grid_search:
    verbose: 100  # Verbosity level for hyperparameter search
    cv: 5  # Number of folds for cross-validation
    scoring: 'roc_auc_score'  # Scoring method for grid search. The higher the better
    refit: 'roc_auc_score'  # Scoring method for refitting the best model. The hyperparameter combination with the highest score will be used for the final refit
    error_score: 'raise'  # Default error handling
    return_train_score: False  # Default setting for returning train scores
    n_jobs: -1  # Default number of jobs to run in parallel

  halving_grid_search:
    verbose: 100  # Verbosity level for hyperparameter search
    cv: 5  # Number of folds for cross-validation
    factor: 3  # Reduction factor for the number of candidates to be kept
    resource: 'n_samples'  # Resource used to early stop the search. Can be either 'n_samples' or 'n_iterations'
    max_resources: 'auto'  # Maximum number of resources to be used
    aggressive_elimination: False  # If true, aggressively eliminate candidates
    scoring: 'roc_auc'  # Scoring method for grid search. The higher the better
    refit: 'roc_auc'  # Scoring method for refitting the best model. The hyperparameter combination with the highest score will be used for the final refit
    random_state: null  # Default random state
    #error_score: 'raise'  # Default error handling
    return_train_score: False  # Default setting for returning train scores
    n_jobs: -1  # Default number of jobs to run in parallel. -1 means all processors
  
  random_search:
    verbose: 100  # Verbosity level for hyperparameter search
    cv: 5  # Number of folds for cross-validation
    n_iter: 1000000  # Number of parameter settings sampled for random search
    # Default parameters for RandomizedSearchCV
    scoring: 'roc_auc_score'  # Scoring method for grid search. The higher the better
    refit: 'roc_auc_score'  # Scoring method for refitting the best model. The hyperparameter combination with the highest score will be used for the final refit
    pre_dispatch: '2*n_jobs'  # Default pre-dispatch configuration
    random_state: null  # Default random state
    error_score: 'raise'  # Default error handling
    return_train_score: False  # Default setting for returning train scores
    n_jobs: -1  # Default number of jobs to run in parallel. -1 means all processors

# Hyperparameter Grid (For use with grid or random search)
# structure:
#   model_type:
#     config_name:
#       hyperparameter_name: [hyperparameter_values]
#       ...
hyperparameter_grid:
  xgbClassifier:
    simple:
      n_estimators: [100, 200, 300, 1000]  # Added extreme upper limit
      max_depth: [3, 6, 9, 15]  # Included a deeper tree option
      learning_rate: [0.01, 0.1, 0.2, 0.001]  # Included a very low learning rate
      subsample: [0.7, 0.8, 0.9, 0.1]  # Added a very low subsample rate
      colsample_bytree: [0.7, 0.8, 0.9, 0.1]  # Included a very low column sample rate
      n_jobs: [null]