{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.insert(0, os.path.abspath(os.path.join(os.getcwd(), '..')))\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "from shared.data_loader import load_dataset_deepcorr\n",
    "from shared.data_processing import generate_flow_pairs \n",
    "from shared.train_test_split import calc_train_test_indexes\n",
    "\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#################### Parameters ####################\n",
    "dataset_path =  \"/home/yagnihotri/datasets/deepcorr_original_dataset\"\n",
    "load_only_flows_with_min_300 = True\n",
    "train_ratio = 0.8\n",
    "flow_size = 300\n",
    "negative_samples = 50\n",
    "\n",
    "#################### Paths ####################\n",
    "run_folder_path = \"./\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading dataset from pickle files...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading progress: 100%|█████████████████████████████████| 10/10 [00:13<00:00,  1.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset length:  7324\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Loading deepcorr dataset\n",
    "deepcorr_dataset = load_dataset_deepcorr(dataset_path, load_only_flows_with_min_300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splitting dataset into training and testing sets...\n",
      "Length of true correlating flow pairs for TRAINING:  5859 flow pairs\n",
      "Length of true correlating flow pairs for TESTING:  1465 flow pairs\n",
      "Generating flow pairs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████| 5859/5859 [00:41<00:00, 142.33it/s]\n",
      "100%|██████████████████████████████████████████████| 1465/1465 [00:09<00:00, 150.34it/s]\n"
     ]
    }
   ],
   "source": [
    "# Split the dataset into training and test sets\n",
    "train_indexes, test_indexes = calc_train_test_indexes(deepcorr_dataset, train_ratio)\n",
    "\n",
    "# Preprocess the data and generate the data arrays for training and testing\n",
    "l2s, labels,l2s_test,labels_test = generate_flow_pairs(deepcorr_dataset, train_indexes, test_indexes, flow_size, run_folder_path, negative_samples)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set size:  298809\n"
     ]
    }
   ],
   "source": [
    "print(\"Training set size: \", len(l2s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(298809, 2400)\n",
      "(74715, 2400)\n"
     ]
    }
   ],
   "source": [
    "l2s_flattened = l2s.reshape(l2s.shape[0], -1)\n",
    "print(l2s_flattened.shape)\n",
    "\n",
    "l2s_test_flattened = l2s_test.reshape(l2s_test.shape[0], -1)  # Same for test data\n",
    "print(l2s_test_flattened.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Sample a subset of your training data\n",
    "subset_size = int(0.1 * l2s_flattened.shape[0])\n",
    "subset_l2s = l2s_flattened[:subset_size]\n",
    "subset_labels = labels[:subset_size]\n",
    "\n",
    "# Time training on the subset\n",
    "start_time = time.time()\n",
    "clf = DecisionTreeClassifier()\n",
    "clf.fit(subset_l2s, subset_labels)\n",
    "training_time_subset = time.time() - start_time\n",
    "\n",
    "# Time prediction and evaluation on a subset of the test data\n",
    "subset_size_test = int(0.1 * l2s_test_flattened.shape[0])\n",
    "subset_l2s_test = l2s_test_flattened[:subset_size_test]\n",
    "subset_labels_test = labels_test[:subset_size_test]\n",
    "\n",
    "start_time = time.time()\n",
    "subset_y_pred = clf.predict(subset_l2s_test)\n",
    "testing_time_subset = time.time() - start_time\n",
    "accuracy = accuracy_score(subset_labels_test, subset_y_pred)\n",
    "\n",
    "# Estimate total training and testing time for the full dataset\n",
    "total_training_estimate = training_time_subset * 10  # Assuming linear scaling\n",
    "total_testing_estimate = testing_time_subset * 10  # Assuming linear scaling\n",
    "total_estimate = total_training_estimate + total_testing_estimate\n",
    "\n",
    "print(f\"Estimated total training time: {total_training_estimate:.2f} seconds\")\n",
    "print(f\"Estimated total testing time: {total_testing_estimate:.2f} seconds\")\n",
    "print(f\"Estimated total time (training + testing): {total_estimate:.2f} seconds\")\n",
    "print(f\"Accuracy on test subset: {accuracy:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a Decision Tree Classifier\n",
    "clf = DecisionTreeClassifier()\n",
    "\n",
    "# Start timing the training process\n",
    "start_time = time.time()\n",
    "\n",
    "# Train the model\n",
    "clf.fit(l2s_flattened, labels)\n",
    "\n",
    "# End timing the training process\n",
    "training_time = time.time() - start_time\n",
    "print(f'Training completed in {training_time:.2f} seconds')\n",
    "\n",
    "# Start timing the prediction process\n",
    "start_time = time.time()\n",
    "\n",
    "# Make predictions\n",
    "y_pred = clf.predict(l2s_test_flattened)\n",
    "\n",
    "# End timing the prediction process\n",
    "testing_time = time.time() - start_time\n",
    "print(f'Testing completed in {testing_time:.2f} seconds')\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(labels_test, y_pred)\n",
    "print(f'Accuracy: {accuracy:.2f}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
